{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbhatti/miniconda3/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import openai\n",
    "from langchain.chains import LLMChain, LLMRouterChain, MultiPromptChain, HypotheticalDocumentEmbedder, RetrievalQA\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Optional\n",
    "import json\n",
    "import pandas as pd\n",
    "from Text_preprocessing import Text_preprocessing\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from typing import List, Dict, Any, Mapping\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "from langchain_community.vectorstores import chroma as Chroma\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from pydantic.v1 import Field\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_transformers import (\n",
    "    LongContextReorder\n",
    ")\n",
    "from sentence_transformers import CrossEncoder\n",
    "import datetime\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    "    context_entity_recall\n",
    ")\n",
    "import llmModels \n",
    "import wandb\n",
    "import pickle\n",
    "import prompts\n",
    "import groundTruths\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "### PARAMETER CHECKPOINT ####\n",
    "\n",
    "#Open AI\n",
    "chatModelAI = ChatOpenAI(temperature=0)\n",
    "\n",
    "# # # # Llama 2 13 B chat\n",
    "# chatModel_llama13b = llmModels.loadLlamma()\n",
    "\n",
    "# # # Mistral 7B chat\n",
    "# chatModel_mistral7b = llmModels.loadMistral7b()\n",
    "\n",
    "# #70B\n",
    "# chatModel_llama70b = llmModels.loadLlama2_70B()\n",
    "\n",
    "## Llama 3 8B\n",
    "llm = llmModels.loadLlama3_8B() \n",
    "\n",
    "##FSD_1777\n",
    "dataPath = \"/home/mbhatti/mnt/d/LLM-repo1/models/langchain_implementation/FSD1777_Oct23.json\"\n",
    "dateFrom = \"2023-10-19T09:00:00+00:00\" #2023-10-19T18:58:41Z for 200 tweets\n",
    "dateTo = \"2023-10-19T18:59:00+00:00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load relevant fields of flood tags api json response\"\"\"\n",
    "def json_dataloader(dataPath = dataPath, dateFrom = dateFrom, dateTo = dateTo):\n",
    "    # Load json and extract relevant records in pandas df\n",
    "    with open(dataPath, 'r') as json_file:\n",
    "        response_dict = json.load(json_file)\n",
    "\n",
    "    # Convert to pandas df    \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    df = pd.DataFrame(response_dict)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.drop(columns=['id','tag_class', 'source', 'lang', 'urls','locations'])\n",
    "\n",
    "    #Get data between thresholds\n",
    "    threshold_datetime_lower = pd.to_datetime(dateFrom)\n",
    "    threshold_datetime_upper = pd.to_datetime(dateTo)\n",
    "    df = df[df['date'] >= threshold_datetime_lower]\n",
    "    df = df[df['date'] <= threshold_datetime_upper]\n",
    "\n",
    "    #Remove duplicates\n",
    "    df  = df.drop_duplicates(subset=[\"text\"], keep=False)\n",
    "    #Pre-process\n",
    "    preprocess = Text_preprocessing(df)\n",
    "    df = preprocess.preprocess()\n",
    "    #Covert date to string\n",
    "    df['date'] = df['date'].astype(str)\n",
    "    return df\n",
    "\n",
    "def bgeEmbeddings():\n",
    "    model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "    # model_name = \"BAAI/bge-m3\"\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "    model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def data_embedding(data : list, eModel = \"bge-large-en-v1.5\", rType = \"Query\", metric = \"L2\", lang = \"en\"):\n",
    "    \"\"\"Vectorize the data using OpenAI embeddings and store in Chroma db\"\"\"\n",
    "    if lang == \"en\":\n",
    "        if eModel != \"bge-large-en-v1.5\":\n",
    "            embeddings = OpenAIEmbeddings()\n",
    "        else:\n",
    "            embeddings = bgeEmbeddings()\n",
    "        \n",
    "        if (rType == \"Hyde\"):\n",
    "            embeddings = hydeEmbedder(embeddings)\n",
    "\n",
    "    if lang == \"ja\":\n",
    "        embeddings = bgeEmbeddings()\n",
    "\n",
    "\n",
    "    documents = []\n",
    "    loader = DataFrameLoader(data, page_content_column=\"text\")\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "    #Change this -- removal of duplicates\n",
    "    db = Chroma.Chroma.from_documents(documents,embeddings)\n",
    "    if db._client.list_collections() != None:\n",
    "        for collection in db._client.list_collections():\n",
    "            ids = collection.get()['ids']\n",
    "            print('REMOVE %s document(s) from %s collection' % (str(len(ids)), collection.name))\n",
    "            if len(ids): collection.delete(ids)\n",
    "\n",
    "    #Create a vector store\n",
    "    if metric == \"cosine\":\n",
    "        db = Chroma.Chroma.from_documents(documents,embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "    else:\n",
    "        db = Chroma.Chroma.from_documents(documents,embeddings)\n",
    "    print(len(db._collection.get()['ids']))\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVE 603 document(s) from langchain collection\n",
      "603\n"
     ]
    }
   ],
   "source": [
    "# llm = chatModel_llama3_8B\n",
    "# Load the data from source\n",
    "# data = dataframe_dataloader()\n",
    "data = json_dataloader()\n",
    "\n",
    "# Convert to vector store\n",
    "vectorstore = data_embedding(data)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbhatti/miniconda3/envs/llama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/mbhatti/miniconda3/envs/llama/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import Tool\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# chat completion llm\n",
    "# llm = ChatOpenAI(\n",
    "#     model_name='gpt-3.5-turbo',\n",
    "#     temperature=0.0\n",
    "# )\n",
    "\n",
    "\n",
    "llmOpenAI = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=1,\n",
    "    return_messages=True,\n",
    "    output_key='output'\n",
    ")\n",
    "\n",
    "\n",
    "#Prompt and chain for Twitter DB-----------------\n",
    "prompt_template_llama3_loc = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Act as a location extractor and extract all relevant locations with respect to the user question.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Answer the question based on the following context only: \n",
    "{context}\n",
    "Question: {question}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "default_prompt = PromptTemplate(template = prompt_template_llama3_loc, input_variables = ['question', 'context'])\n",
    "\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": default_prompt},\n",
    "    verbose = True,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "\n",
    "#Prompt and chain for extracting geolocations --------------\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "geoLocTemplate = \"\"\"\n",
    "Act as geo locator. Extract the geopoint coordinates according to the question in the following json format: \n",
    "{{'location':'Location name', \n",
    "'latitude' : 12.2,\n",
    "'longitude' : 2.33\n",
    "}}\n",
    "\n",
    "question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=geoLocTemplate,\n",
    ")\n",
    "# description = \"It is software dev firm specifically focusing on automation software\"\n",
    "# prompt_template.format(firm_description=description)\n",
    "llmGPT40 = ChatOpenAI(\n",
    "    model_name='gpt-4o',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "chaingeo = LLMChain(llm=llmGPT40, prompt=prompt_template)   \n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Twitter database',\n",
    "        func=qa.invoke,\n",
    "        description=(\n",
    "            'Use this tool to answer flooding related questions'\n",
    "        )\n",
    "    ),\n",
    "    Tool(\n",
    "    name='Geo location extraction',\n",
    "    func=chaingeo.run,\n",
    "    description=(\n",
    "        'Use this tool to extract geolocation coordinates'\n",
    "    )\n",
    "    )\n",
    "]\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# conv\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llmOpenAI,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Geo location extraction\",\n",
      "    \"action_input\": \"North Sea, North Shields, South Shields, Barbourne (Worcester), River Maun (near Retford), Bridlington (Yorkshire), Scarborough (Yorkshire), Tyne (at North and South Shields), Aberdeenshire, Angus, Dundee, Perth & Kinross, Kintore, Inverurie, Perthshire, Findhorn, Nairn, Moray, Speyside, Brechin, River Don (Aberdeenshire), River Isla (Blairgowrie), Haughton, Milton, West Drayton (Nottinghamshire), Sandsend (North Yorkshire), Glenrothes, River South Esk (Angus), Ireland\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m```json\n",
      "[\n",
      "    {'location': 'North Sea', 'latitude': 56.0, 'longitude': 3.0},\n",
      "    {'location': 'North Shields', 'latitude': 55.008, 'longitude': -1.447},\n",
      "    {'location': 'South Shields', 'latitude': 54.998, 'longitude': -1.432},\n",
      "    {'location': 'Barbourne (Worcester)', 'latitude': 52.204, 'longitude': -2.224},\n",
      "    {'location': 'River Maun (near Retford)', 'latitude': 53.322, 'longitude': -0.943},\n",
      "    {'location': 'Bridlington (Yorkshire)', 'latitude': 54.084, 'longitude': -0.200},\n",
      "    {'location': 'Scarborough (Yorkshire)', 'latitude': 54.280, 'longitude': -0.404},\n",
      "    {'location': 'Tyne (at North and South Shields)', 'latitude': 55.000, 'longitude': -1.450},\n",
      "    {'location': 'Aberdeenshire', 'latitude': 57.149, 'longitude': -2.094},\n",
      "    {'location': 'Angus', 'latitude': 56.697, 'longitude': -2.895},\n",
      "    {'location': 'Dundee', 'latitude': 56.462, 'longitude': -2.970},\n",
      "    {'location': 'Perth & Kinross', 'latitude': 56.395, 'longitude': -3.431},\n",
      "    {'location': 'Kintore', 'latitude': 57.234, 'longitude': -2.345},\n",
      "    {'location': 'Inverurie', 'latitude': 57.284, 'longitude': -2.379},\n",
      "    {'location': 'Perthshire', 'latitude': 56.704, 'longitude': -3.729},\n",
      "    {'location': 'Findhorn', 'latitude': 57.653, 'longitude': -3.608},\n",
      "    {'location': 'Nairn', 'latitude': 57.580, 'longitude': -3.872},\n",
      "    {'location': 'Moray', 'latitude': 57.613, 'longitude': -3.308},\n",
      "    {'location': 'Speyside', 'latitude': 57.476, 'longitude': -3.333},\n",
      "    {'location': 'Brechin', 'latitude': 56.731, 'longitude': -2.656},\n",
      "    {'location': 'River Don (Aberdeenshire)', 'latitude': 57.150, 'longitude': -2.100},\n",
      "    {'location': 'River Isla (Blairgowrie)', 'latitude': 56.591, 'longitude': -3.340},\n",
      "    {'location': 'Haughton', 'latitude': 53.330, 'longitude': -2.100},\n",
      "    {'location': 'Milton', 'latitude': 51.360, 'longitude': -0.960},\n",
      "    {'location': 'West Drayton (Nottinghamshire)', 'latitude': 53.274, 'longitude': -0.947},\n",
      "    {'location': 'Sandsend (North Yorkshire)', 'latitude': 54.506, 'longitude': -0.671},\n",
      "    {'location': 'Glenrothes', 'latitude': 56.196, 'longitude': -3.174},\n",
      "    {'location': 'River South Esk (Angus)', 'latitude': 56.697, 'longitude': -2.895},\n",
      "    {'location': 'Ireland', 'latitude': 53.142, 'longitude': -7.692}\n",
      "]\n",
      "```\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The geo point locations of the mentioned places are as follows: North Sea (56.0, 3.0), North Shields (55.008, -1.447), South Shields (54.998, -1.432), Barbourne (Worcester) (52.204, -2.224), River Maun (near Retford) (53.322, -0.943), Bridlington (Yorkshire) (54.084, -0.200), Scarborough (Yorkshire) (54.280, -0.404), Tyne (at North and South Shields) (55.000, -1.450), Aberdeenshire (57.149, -2.094), Angus (56.697, -2.895), Dundee (56.462, -2.970), Perth & Kinross (56.395, -3.431), Kintore (57.234, -2.345), Inverurie (57.284, -2.379), Perthshire (56.704, -3.729), Findhorn (57.653, -3.608), Nairn (57.580, -3.872), Moray (57.613, -3.308), Speyside (57.476, -3.333), Brechin (56.731, -2.656), River Don (Aberdeenshire) (57.150, -2.100), River Isla (Blairgowrie) (56.591, -3.340), Haughton (53.330, -2.100), Milton (51.360, -0.960), West Drayton (Nottinghamshire) (53.274, -0.947), Sandsend (North Yorkshire) (54.506, -0.671), Glenrothes (56.196, -3.174), River South Esk (Angus) (56.697, -2.895), Ireland (53.142, -7.692)\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# query = \"\"\"Which locations received flood warnings?\"\"\"\n",
    "query = \"What are the geo point locations of these places?\"\n",
    "results = agent(query)\n",
    "# results = agent_executor.invoke({\"input\": \"Which locations are receiving flood warnings\"})\n",
    "# agent.invoke({\"input\": \"Any deaths reported due to flooding?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What are the geo point locations of these places?', 'chat_history': [HumanMessage(content='Which locations received flood warnings?'), AIMessage(content='The locations that received flood warnings are: North Sea, North Shields, South Shields, Barbourne (Worcester), River Maun (near Retford), Bridlington (Yorkshire), Scarborough (Yorkshire), Tyne (at North and South Shields), Aberdeenshire, Angus, Dundee, Perth & Kinross, Kintore, Inverurie, Perthshire, Findhorn, Nairn, Moray, Speyside, Brechin, River Don (Aberdeenshire), River Isla (Blairgowrie), Haughton, Milton, West Drayton (Nottinghamshire), Sandsend (North Yorkshire), Glenrothes, River South Esk (Angus), and Ireland.')], 'output': 'The geo point locations of the mentioned places are as follows: North Sea (56.0, 3.0), North Shields (55.008, -1.447), South Shields (54.998, -1.432), Barbourne (Worcester) (52.204, -2.224), River Maun (near Retford) (53.322, -0.943), Bridlington (Yorkshire) (54.084, -0.200), Scarborough (Yorkshire) (54.280, -0.404), Tyne (at North and South Shields) (55.000, -1.450), Aberdeenshire (57.149, -2.094), Angus (56.697, -2.895), Dundee (56.462, -2.970), Perth & Kinross (56.395, -3.431), Kintore (57.234, -2.345), Inverurie (57.284, -2.379), Perthshire (56.704, -3.729), Findhorn (57.653, -3.608), Nairn (57.580, -3.872), Moray (57.613, -3.308), Speyside (57.476, -3.333), Brechin (56.731, -2.656), River Don (Aberdeenshire) (57.150, -2.100), River Isla (Blairgowrie) (56.591, -3.340), Haughton (53.330, -2.100), Milton (51.360, -0.960), West Drayton (Nottinghamshire) (53.274, -0.947), Sandsend (North Yorkshire) (54.506, -0.671), Glenrothes (56.196, -3.174), River South Esk (Angus) (56.697, -2.895), Ireland (53.142, -7.692)', 'intermediate_steps': [(AgentAction(tool='Geo location extraction', tool_input='North Sea, North Shields, South Shields, Barbourne (Worcester), River Maun (near Retford), Bridlington (Yorkshire), Scarborough (Yorkshire), Tyne (at North and South Shields), Aberdeenshire, Angus, Dundee, Perth & Kinross, Kintore, Inverurie, Perthshire, Findhorn, Nairn, Moray, Speyside, Brechin, River Don (Aberdeenshire), River Isla (Blairgowrie), Haughton, Milton, West Drayton (Nottinghamshire), Sandsend (North Yorkshire), Glenrothes, River South Esk (Angus), Ireland', log='```json\\n{\\n    \"action\": \"Geo location extraction\",\\n    \"action_input\": \"North Sea, North Shields, South Shields, Barbourne (Worcester), River Maun (near Retford), Bridlington (Yorkshire), Scarborough (Yorkshire), Tyne (at North and South Shields), Aberdeenshire, Angus, Dundee, Perth & Kinross, Kintore, Inverurie, Perthshire, Findhorn, Nairn, Moray, Speyside, Brechin, River Don (Aberdeenshire), River Isla (Blairgowrie), Haughton, Milton, West Drayton (Nottinghamshire), Sandsend (North Yorkshire), Glenrothes, River South Esk (Angus), Ireland\"\\n}\\n```'), \"```json\\n[\\n    {'location': 'North Sea', 'latitude': 56.0, 'longitude': 3.0},\\n    {'location': 'North Shields', 'latitude': 55.008, 'longitude': -1.447},\\n    {'location': 'South Shields', 'latitude': 54.998, 'longitude': -1.432},\\n    {'location': 'Barbourne (Worcester)', 'latitude': 52.204, 'longitude': -2.224},\\n    {'location': 'River Maun (near Retford)', 'latitude': 53.322, 'longitude': -0.943},\\n    {'location': 'Bridlington (Yorkshire)', 'latitude': 54.084, 'longitude': -0.200},\\n    {'location': 'Scarborough (Yorkshire)', 'latitude': 54.280, 'longitude': -0.404},\\n    {'location': 'Tyne (at North and South Shields)', 'latitude': 55.000, 'longitude': -1.450},\\n    {'location': 'Aberdeenshire', 'latitude': 57.149, 'longitude': -2.094},\\n    {'location': 'Angus', 'latitude': 56.697, 'longitude': -2.895},\\n    {'location': 'Dundee', 'latitude': 56.462, 'longitude': -2.970},\\n    {'location': 'Perth & Kinross', 'latitude': 56.395, 'longitude': -3.431},\\n    {'location': 'Kintore', 'latitude': 57.234, 'longitude': -2.345},\\n    {'location': 'Inverurie', 'latitude': 57.284, 'longitude': -2.379},\\n    {'location': 'Perthshire', 'latitude': 56.704, 'longitude': -3.729},\\n    {'location': 'Findhorn', 'latitude': 57.653, 'longitude': -3.608},\\n    {'location': 'Nairn', 'latitude': 57.580, 'longitude': -3.872},\\n    {'location': 'Moray', 'latitude': 57.613, 'longitude': -3.308},\\n    {'location': 'Speyside', 'latitude': 57.476, 'longitude': -3.333},\\n    {'location': 'Brechin', 'latitude': 56.731, 'longitude': -2.656},\\n    {'location': 'River Don (Aberdeenshire)', 'latitude': 57.150, 'longitude': -2.100},\\n    {'location': 'River Isla (Blairgowrie)', 'latitude': 56.591, 'longitude': -3.340},\\n    {'location': 'Haughton', 'latitude': 53.330, 'longitude': -2.100},\\n    {'location': 'Milton', 'latitude': 51.360, 'longitude': -0.960},\\n    {'location': 'West Drayton (Nottinghamshire)', 'latitude': 53.274, 'longitude': -0.947},\\n    {'location': 'Sandsend (North Yorkshire)', 'latitude': 54.506, 'longitude': -0.671},\\n    {'location': 'Glenrothes', 'latitude': 56.196, 'longitude': -3.174},\\n    {'location': 'River South Esk (Angus)', 'latitude': 56.697, 'longitude': -2.895},\\n    {'location': 'Ireland', 'latitude': 53.142, 'longitude': -7.692}\\n]\\n```\")]}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtool)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#FOR TWITTER DATABASE\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Get response\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data = results['intermediate_steps'][0]\n",
    "print(results['intermediate_steps'][0][0].tool)\n",
    "\n",
    "#FOR TWITTER DATABASE\n",
    "\n",
    "#Get response\n",
    "if results['intermediate_steps'][0][0].tool == \"Twitter database\":\n",
    "    print(results['intermediate_steps'][0][1]['result'])\n",
    "\n",
    "#Get source docs\n",
    "if results['intermediate_steps'][0][0].tool == \"Twitter database\":\n",
    "    print(results['intermediate_steps'][0][1]['source_documents'])\n",
    "\n",
    "# FOR GEO LOCATION\n",
    "\n",
    "# Get response\n",
    "if results['intermediate_steps'][0][0].tool == \"Geo location extraction\":\n",
    "    print(results['intermediate_steps'][0][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "geoLocTemplate = \"\"\"\n",
    "Act as geo locator. Extract the geopoint coordinates according to the question in the following json format: \n",
    "{{'location':'Location name', \n",
    "'latitude' : 12.2,\n",
    "'longitude' : 2.33\n",
    "}}\n",
    "\n",
    "question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=geoLocTemplate,\n",
    ")\n",
    "# description = \"It is software dev firm specifically focusing on automation software\"\n",
    "# prompt_template.format(firm_description=description)\n",
    "chain = LLMChain(llm=llmOpenAI, prompt=prompt_template)   \n",
    "# chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "print(chain.run(\"What is geo location of London, Manchester, Brechin and Angus\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
